{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1db4466",
   "metadata": {},
   "source": [
    "# Scientific literature mining\n",
    "\n",
    "Using embeddings, we will mine scientific litterature to identify relationships between papers and find similar papers.\n",
    "\n",
    "We already have extracted title and abstract for several preprints from arXiv. These papers are taken from multiple topics:\n",
    "- *nanoporous materials*\n",
    "- *many-body*\n",
    "- *machine learning*\n",
    "- *quantum computing*\n",
    "- *biomolecular modeling*\n",
    "\n",
    "## Load required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1e7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from fastembed import TextEmbedding\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecfa1e",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e303b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa171d7b8374b118051bd6778d6db3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TextEmbedding(\"nomic-ai/nomic-embed-text-v1.5-Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448abc5",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421f60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open(\"arxiv_papers.json\")\n",
    "papers = json.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b39488",
   "metadata": {},
   "source": [
    "Display number of papers and the first record of the paper dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5ca085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers: 400\n",
      "First paper:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/2402.01321v1',\n",
       " 'date': '2024-02-02T11:17:55Z',\n",
       " 'title': 'Ionic Current Rectification in Nanopores: Effects of Nanopore Material, Electrolyte and Surface Treatment',\n",
       " 'abstract': 'Ionic Current Rectification (ICR) can appear in nanopores, causing a diode-like behavior that originates from different efficiency of ion transport through the pore channel with respect to the applied voltage bias polarity. This effect is particularly interesting for nanopores with a short channel length, that is smaller than 500 nm, because then the dependence of the ion current on the direction along which the ions pass through the channel is determined by the geometry and material of the nanopore, and by the ion concentration in the electrolyte. Surface charges can play an important role, and therefore nanopores consisting of multiple materials can induce ICR because of different charge distributions at the nanopore-electrolyte interface for the different material sections. In this work, we study four solid-state nanopore designs considering different geometries of charge distributions along the inner and outer surfaces of nanopores, and evaluate their impact on ICR with six different electrolytes. The direct comparison between experimental data and modeling enables to understand how the different surface charge configurations impact the ICR.',\n",
       " 'query': 'nanoporous materials'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of papers: {len(papers)}\")\n",
    "print(\"First paper:\")\n",
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b852da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f873b9c9a480f8f702743e4f3edeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange, tqdm\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m tqdm(papers):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabstract\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workp/misc/events/2025-05-26_CECAM_summer_school/handson-scientific-literature-embeddings/.venv/lib/python3.12/site-packages/fastembed/text/text_embedding.py:107\u001b[39m, in \u001b[36mTextEmbedding.embed\u001b[39m\u001b[34m(self, documents, batch_size, parallel, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     87\u001b[39m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m     **kwargs,\n\u001b[32m     91\u001b[39m ) -> Iterable[np.ndarray]:\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[33;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.embed(documents, batch_size, parallel, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workp/misc/events/2025-05-26_CECAM_summer_school/handson-scientific-literature-embeddings/.venv/lib/python3.12/site-packages/fastembed/text/onnx_embedding.py:262\u001b[39m, in \u001b[36mOnnxTextEmbedding.embed\u001b[39m\u001b[34m(self, documents, batch_size, parallel, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    241\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    242\u001b[39m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m     **kwargs,\n\u001b[32m    246\u001b[39m ) -> Iterable[np.ndarray]:\n\u001b[32m    247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    260\u001b[39m \u001b[33;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed_documents(\n\u001b[32m    263\u001b[39m         model_name=\u001b[38;5;28mself\u001b[39m.model_name,\n\u001b[32m    264\u001b[39m         cache_dir=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.cache_dir),\n\u001b[32m    265\u001b[39m         documents=documents,\n\u001b[32m    266\u001b[39m         batch_size=batch_size,\n\u001b[32m    267\u001b[39m         parallel=parallel,\n\u001b[32m    268\u001b[39m         providers=\u001b[38;5;28mself\u001b[39m.providers,\n\u001b[32m    269\u001b[39m         cuda=\u001b[38;5;28mself\u001b[39m.cuda,\n\u001b[32m    270\u001b[39m         device_ids=\u001b[38;5;28mself\u001b[39m.device_ids,\n\u001b[32m    271\u001b[39m         **kwargs,\n\u001b[32m    272\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workp/misc/events/2025-05-26_CECAM_summer_school/handson-scientific-literature-embeddings/.venv/lib/python3.12/site-packages/fastembed/text/onnx_text_model.py:118\u001b[39m, in \u001b[36mOnnxTextModel._embed_documents\u001b[39m\u001b[34m(self, model_name, cache_dir, documents, batch_size, parallel, providers, cuda, device_ids, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m         \u001b[38;5;28mself\u001b[39m.load_onnx_model()\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(documents, batch_size):\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post_process_onnx_output(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43monnx_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parallel == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workp/misc/events/2025-05-26_CECAM_summer_school/handson-scientific-literature-embeddings/.venv/lib/python3.12/site-packages/fastembed/text/onnx_text_model.py:85\u001b[39m, in \u001b[36mOnnxTextModel.onnx_embed\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     onnx_input[\u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m] = np.array(\n\u001b[32m     80\u001b[39m         [np.zeros(\u001b[38;5;28mlen\u001b[39m(e), dtype=np.int64) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m input_ids], dtype=np.int64\n\u001b[32m     81\u001b[39m     )\n\u001b[32m     83\u001b[39m onnx_input = \u001b[38;5;28mself\u001b[39m._preprocess_onnx_input(onnx_input, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m model_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mONNX_OUTPUT_NAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m OnnxOutputContext(\n\u001b[32m     87\u001b[39m     model_output=model_output[\u001b[32m0\u001b[39m],\n\u001b[32m     88\u001b[39m     attention_mask=onnx_input.get(\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, attention_mask),\n\u001b[32m     89\u001b[39m     input_ids=onnx_input.get(\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, input_ids),\n\u001b[32m     90\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workp/misc/events/2025-05-26_CECAM_summer_school/handson-scientific-literature-embeddings/.venv/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, output_names, input_feed, run_options)\u001b[39m\n\u001b[32m    218\u001b[39m     output_names = [output.name \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._outputs_meta]\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m C.EPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_fallback:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for paper in tqdm(papers):\n",
    "    list(model.embed(paper[\"title\"] + paper[\"abstract\"]))[0]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c9680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
